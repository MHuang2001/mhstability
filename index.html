<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Automatic Threshold Selection, used in extension for stabs package. ">
<title>Stability Selection with Automatic Threshold Selection using Maximum Likelihood • mhstability</title>
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="Stability Selection with Automatic Threshold Selection using Maximum Likelihood">
<meta property="og:description" content="Automatic Threshold Selection, used in extension for stabs package. ">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-default navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="index.html">mhstability</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="reference/index.html">References</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9"><div class="section level1">
<div class="page-header"><h1 id="mhstability">mhstability<a class="anchor" aria-label="anchor" href="#mhstability"></a>
</h1></div>
<p>Stability Selection Visualisation Tool with Automatic Threshold Selection.</p>
<p>Extends stability selection and introduces automatic threshold selection to compute a data-adaptive stability cutoff. This is an R Package created to complement the use of stabs objects from the stabs package. It visualises variable selection probability and likelihood function through <code>plot_stabs</code>. The package also includes an <code>ats</code> function to compute the threshold.</p>
</div>
<div class="section level1">
<h1 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h1>
<p>Install package via GitHub</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">devtools</span><span class="fu">::</span><span class="fu">install_github</span><span class="op">(</span><span class="st">"MHuang2001/mhstability"</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mhuang2001.github.io/mhstability/">mhstability</a></span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level1">
<h1 id="usage">Usage<a class="anchor" aria-label="anchor" href="#usage"></a>
</h1>
<p>The main function to create a stabs object and conduct stability selection using the <code>stabs</code> package:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">s</span> <span class="op">=</span> <span class="fu">stabs</span><span class="fu">::</span><span class="fu">stabsel</span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, <span class="va">cutoff</span>, <span class="va">PFER</span><span class="op">)</span></span></code></pre></div>
<p>The object <code>s</code> can be inputted into the function <code><a href="reference/plot_stabs.html">mhstability::plot_stabs</a></code>, to plot the variable selection probability scree plot. It automatically computes the automatic threshold selection (ATS) rate <span class="math inline"><em>π̂</em></span>. This can be manually found using the <code>ats</code> function. The function can also plot the likelihood function, used to determine the optimal threshold.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Plot variable selection probability scree plot</span></span>
<span><span class="fu"><a href="reference/plot_stabs.html">plot_stabs</a></span><span class="op">(</span><span class="va">s</span>, which <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot likelihood function</span></span>
<span><span class="fu"><a href="reference/plot_stabs.html">plot_stabs</a></span><span class="op">(</span><span class="va">s</span>, which <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot variable selection probability scree plot with respect to manual threshold selection and display top 4 variables</span></span>
<span><span class="fu"><a href="reference/plot_stabs.html">plot_stabs</a></span><span class="op">(</span><span class="va">s</span>, which <span class="op">=</span> <span class="fl">1</span>, threshold <span class="op">=</span> <span class="st">"MTS"</span>, top <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot variable selection probability scree plot with respect to automatic threshold selection and display all selected variables</span></span>
<span><span class="fu"><a href="reference/plot_stabs.html">plot_stabs</a></span><span class="op">(</span><span class="va">s</span>, which <span class="op">=</span> <span class="fl">1</span>, threshold <span class="op">=</span> <span class="st">"ATS"</span>, top <span class="op">=</span> <span class="st">"all"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute elbow index</span></span>
<span><span class="fu"><a href="reference/ats.html">ats</a></span><span class="op">(</span><span class="va">s</span>, type <span class="op">=</span> <span class="st">"index"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute ATS cutoff</span></span>
<span><span class="fu"><a href="reference/ats.html">ats</a></span><span class="op">(</span><span class="va">s</span>, type <span class="op">=</span> <span class="st">"prob"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level1">
<h1 id="theory">Theory<a class="anchor" aria-label="anchor" href="#theory"></a>
</h1>
<p>Stability selection (SS)  is a simple process that utilises subsampling and randomness to improve the performance of a variable selection algorithm. SS is based on the aggregation of results, given by repeated variable selection algorithms on multiple subsamples of the data. A key feature of SS is an error bound, which can be controlled by modifying various parameters. Therefore, a practitioner can tailor their tolerance for error simply by changing the parameters. SS aims to improve the performance of existing variable selection algorithms and construct a theoretical error control.</p>
<div class="section level2">
<h2 id="framework">Framework<a class="anchor" aria-label="anchor" href="#framework"></a>
</h2>
<p>Any variable selection algorithm aims to estimate the set of signal features <span class="math inline"><em>S</em></span>. With features indexed from <span class="math inline">{1, …, <em>p</em>}</span>, we let <span class="math inline"><em>S</em> ⊆ {1, …, <em>p</em>}</span> and the set of Noise variables <span class="math inline"><em>N</em> = {1, …, <em>p</em>} ∖ <em>S</em></span>. This is equivalent to a set of signal variables containing non-zero coefficients, <span class="math inline"><em>S</em> = {<em>k</em> : <em>β</em><sub><em>k</em></sub> ≠ 0}</span>, inverse to the set of noise variables containing a coefficient of zero, <span class="math inline"><em>N</em> = {<em>k</em> : <em>β</em><sub><em>k</em></sub> = 0}</span>. The estimation of the set of signal features <span class="math inline"><em>Ŝ</em></span> are the selected variables given by some feature selection algorithm, such as LASSO. In feature selection algorithms that have a regularisation parameter <span class="math inline"><em>λ</em></span> such as LASSO, Stepwise Selection, Elastic Net, we note that <span class="math inline"><em>Ŝ</em></span> is a function of <span class="math inline"><em>λ</em></span>, and such denote <span class="math inline"><em>Ŝ</em><sup><em>λ</em></sup> = {<em>k</em> : <em>β</em><sub><em>k</em></sub> ≠ 0}, <em>k</em> = 1, …, <em>p</em></span> the set of selected variables for <span class="math inline"><em>λ</em> ∈ <em>Λ</em></span>. For every value of <span class="math inline"><em>λ</em> ∈ <em>Λ</em></span>, the feature selection algorithm will estimate <span class="math inline"><em>Ŝ</em><sup><em>λ</em></sup></span> with the goal of selecting the right <span class="math inline"><em>Ŝ</em><sup><em>λ</em></sup></span> such that the probability of the selected <span class="math inline"><em>Ŝ</em><sup><em>λ</em></sup></span> is identical to the true set <span class="math inline"><em>S</em></span> with high probability. Formally, we aim that consistent variable selection (or stability of the variables) is equivalent to <span class="math inline">ℙ(<em>Ŝ</em><sup><em>λ</em></sup>=<em>S</em>) → 1</span>. Each estimated set is derived from a subsample of the data <span class="math inline"><em>I</em></span>. A useful visualisation is a regularisation path when determining the optimal value of <span class="math inline"><em>λ</em> ∈ <em>Λ</em></span>. This regularisation path shows the coefficient of all variables for all values of <span class="math inline"><em>λ</em></span>; <span class="math inline">{<em>β̂</em><sub><em>k</em></sub><sup><em>λ</em></sup>; <em>λ</em> ∈ <em>Λ</em>, <em>k</em> = 1, …, <em>p</em>}</span>. An extension to the regularisation path is the stability path, which replaces the coefficients of the variables, with the probability of each variable being selected when randomly resampling from the data.</p>
<p>Let <span class="math inline"><em>I</em></span> be a random subsample of <span class="math inline">{1, …, <em>n</em>}</span> (<span class="math inline"><em>n</em>=</span> number of entries), of equal probabilities with size <span class="math inline">$\lfloor \frac{n}{2}\rfloor$</span> drawn without replacement. Let <span class="math inline"><em>Ŝ</em><sup><em>λ</em></sup>(<em>I</em>)</span> represent the subsample as a function of <span class="math inline"><em>I</em></span> and some regularisation parameter <span class="math inline"><em>λ</em></span>.</p>
<p>Let <span class="math inline"><em>K</em> ⊆ {1, …, <em>p</em>}</span> denote every set of features <span class="math inline"><em>p</em></span>. Then, the probability of a set of features in the selected set <span class="math inline"><em>Ŝ</em><sup><em>λ</em></sup>(<em>I</em>)</span> is <span class="math display">$$\hat{\mathbb{P}i}^\lambda _K  = \mathbb{P} \left(K\subseteq \hat{S} ^\lambda (I)\right)$$</span></p>
<p>An attractive property of SS is that there can be derived a bound for the expected number <span class="math inline"><em>V</em></span> of falsely selected variables, where <span class="math inline"><em>V</em> = |<em>N</em>∩<em>Ŝ</em><sup>stable</sup>|</span>. Our definition of a falsely selected variable is a variable that is deemed stable when in reality belongs to the noise set <span class="math inline"><em>N</em></span>. Denote that <span class="math inline"><em>Ŝ</em><sup><em>Λ</em></sup> = ⋃<sub><em>λ</em> ∈ <em>Λ</em></sub><em>Ŝ</em><sup><em>λ</em></sup></span> is the union of the set of selected variables for all varying regularisation parameter <span class="math inline"><em>λ</em></span>. Then <span class="math inline">$q_\Lambda = \E (|\hat{S} ^\Lambda (I)| )$</span> is the average number of selected variables per run. An error bound or the maximum number of allowed falsely selected variables can be mathematically described by incorporating <span class="math inline"><em>q</em><sub><em>Λ</em></sub></span>, <span class="math inline">ℙ<em>i</em></span>, and the number of features <span class="math inline"><em>p</em></span>. While this error bound is helpful, it is more of a theoretical advantage, as it requires assumptions, including the exchangeability of the noise variables. Given that this exchangeability assumption for the noise variables is quite hard to prove in practice, Shah &amp; Samworth (2013) introduced their version of SS, Complementary Pairs Stability Selection (CPSS), which requires no exchangeability assumption. The authors introduce a different sampling method, straying away from random subsampling that the original authors utilises. This new sampling method features samples from the data set with the same size <span class="math inline">$\lfloor \frac{n}{2}\rfloor$</span> and has no intersect.</p>
<p>Let the subsamples be drawn as complementary pairs from <span class="math inline">{1, …, <em>n</em>}</span>. Then the subsampling procedure outputs index sets <span class="math inline">{(<em>A</em><sub>2<em>j</em> − 1</sub>,<em>A</em><sub>2<em>j</em></sub>) : <em>j</em> = 1, …, <em>B</em>}</span>, where each <span class="math inline"><em>A</em><sub><em>j</em></sub></span> is a subset of <span class="math inline">{1, …, <em>n</em>}</span> of size <span class="math inline">$\lfloor \frac{n}{2}\rfloor$</span> and <span class="math inline"><em>A</em><sub>2<em>j</em> − 1</sub> ∩ <em>A</em><sub>2<em>j</em></sub> = ∅</span>. For <span class="math inline">ℙ<em>i</em> ∈ [0,1]</span>, the simultaneous selection version of <span class="math inline"><em>Ŝ</em><sub><em>n</em></sub></span> is <span class="math inline">$\hat{S}^{\text{CPSS}} _{n,\mathbb{P}i} = \{k:\hat{\mathbb{P}i}_B (k) \geq \mathbb{P}i \}$</span>, where the function <span class="math inline">$\hat{\mathbb{P}i}_B:\{1,\dots,p\} \rightarrow \{0, 1/(2B),1/B,\dots, B\}$</span> is given by</p>
<p><span class="math display">$$\hat{\mathbb{P}i} _B (k) = \frac{1}{2B} \sum^{2B} _{j=1} \mathbf{1}_{k\in \hat{S} (A_{j})} $$</span></p>
<p>The methodology and steps between using SS and CPSS do not change, and the steps hereafter in determining the stable set <span class="math inline"><em>Ŝ</em></span> are identical. The difference lies in the sampling step. Given that the data is sampled in pairs and twice at a time, the authors recommend letting <span class="math inline"><em>B</em> = 50</span>, yielding <span class="math inline">100</span> samples, the same number of samples as SS when <span class="math inline"><em>B</em> = 100</span>. Since the pairs <span class="math inline"><em>A</em><sub>2<em>j</em> − 1</sub> ∩ <em>A</em><sub>2<em>j</em></sub> = ∅</span> and <span class="math inline"><em>A</em><sub>2<em>j</em> − 1</sub> ∪ <em>A</em><sub>2<em>j</em></sub> = <em>A</em></span>, where <span class="math inline"><em>A</em></span> is the set of all data points, there is no loss in data due to chance, as this sampling process always considers all data points. This mitigates the possible loss of information in SS, as the random subsampling has no guarantee that all information is used.</p>
<p><span class="math display">$$\hat{\mathbb{P}i} _B (k) = \frac{1}{2B} \sum^{2B} _{j=1} \mathbf{1}_{k\in \hat{S} (A_{j})} $$</span></p>
</div>
</div>
<div class="section level1">
<h1 id="notice">Notice<a class="anchor" aria-label="anchor" href="#notice"></a>
</h1>
<p>This work has been created as part of my Honours degree at the University of Sydney 2023.</p>
</div>
<div class="section level1">
<h1 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h1>
<ul>
<li><p>Meinshausen, N. and Buehlmann, P. (2009). Stability Selection. arXiv:0809.2932 [stat]</p></li>
<li><p>Shah, R. D. and Samworth, R. J. (2013). Variable selection with error control: another look at stability selection. Journal of the Royal Statistical Society. Series B (Statistical Methodology), 75(1):55–80. Publisher: Wiley.</p></li>
<li><p>Hofner, B. and Hothorn, T. (2021). stabs: Stability Selection with Error Control.</p></li>
<li><p>Zhu, M. and Ghodsi, A. (2006). Automatic dimensionality selection from the scree plot via the use of profile likelihood. Computational Statistics &amp; Data Analysis, 51(2):918–930.</p></li>
</ul>
</div>

  </main><aside class="col-md-3"><div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li>What license is it under?</li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing mhstability</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Martin Huang <br><small class="roles"> Author, maintainer </small>  </li>
</ul>
</div>



  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Martin Huang.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
